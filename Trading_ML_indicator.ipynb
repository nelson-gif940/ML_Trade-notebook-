{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpApUWQXnmUKnMAttn5Un2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"AH2i1hsT6BnE","executionInfo":{"status":"ok","timestamp":1729772379120,"user_tz":-120,"elapsed":11961,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import PIL\n","import tensorflow as tf\n","import pathlib\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G33OaM9I8D7F","executionInfo":{"status":"ok","timestamp":1729772404875,"user_tz":-120,"elapsed":25774,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}},"outputId":"364c0450-f3c2-4a0d-f729-f4ac6158446e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["data_dir = pathlib.Path('/content/drive/MyDrive/MLPics2022/')"],"metadata":{"id":"bTqT3MQH6iP5","executionInfo":{"status":"ok","timestamp":1729772406459,"user_tz":-120,"elapsed":292,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","img_height = 180\n","img_width = 180"],"metadata":{"id":"lQKJMyUy6p0E","executionInfo":{"status":"ok","timestamp":1729772407779,"user_tz":-120,"elapsed":8,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=124,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","normalization_layer = layers.Rescaling(1./255)\n","\n","normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","image_batch, labels_batch = next(iter(normalized_ds))\n","first_image = image_batch[0]\n","print(np.min(first_image), np.max(first_image))\n","\n","class_names = train_ds.class_names\n","print(class_names)\n","num_classes = len(class_names)\n","\n","model = Sequential([\n","  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(num_classes)\n","])\n","\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n","epochs=10\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOlx0eJo60Ac","executionInfo":{"status":"ok","timestamp":1729772626287,"user_tz":-120,"elapsed":217566,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}},"outputId":"13c4f396-ee6c-4a7c-d6e8-23be31e57727"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 286 files belonging to 8 classes.\n","Using 229 files for training.\n","Found 286 files belonging to 8 classes.\n","Using 57 files for validation.\n","0.0 1.0\n","['Buy_-1', 'Buy_10', 'Buy_2', 'Buy_5', 'Sell_-1', 'Sell_10', 'Sell_2', 'Sell_5']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - accuracy: 0.2926 - loss: 1.7361 - val_accuracy: 0.4737 - val_loss: 1.4634\n","Epoch 2/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.5590 - loss: 1.2945 - val_accuracy: 0.4737 - val_loss: 1.3646\n","Epoch 3/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.6692 - loss: 0.9633 - val_accuracy: 0.7018 - val_loss: 1.0710\n","Epoch 4/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.7791 - loss: 0.6468 - val_accuracy: 0.7193 - val_loss: 0.9807\n","Epoch 5/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.9114 - loss: 0.3045 - val_accuracy: 0.6491 - val_loss: 1.3942\n","Epoch 6/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9248 - loss: 0.2549 - val_accuracy: 0.8070 - val_loss: 1.0852\n","Epoch 7/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9784 - loss: 0.0692 - val_accuracy: 0.7895 - val_loss: 1.1522\n","Epoch 8/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.8246 - val_loss: 1.4509\n","Epoch 9/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7895 - val_loss: 1.5728\n","Epoch 10/10\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7895 - val_loss: 1.6783\n"]}]},{"cell_type":"code","source":["img = tf.keras.utils.load_img(\n","    '/content/drive/MyDrive/Testing/57_sell_10.gif', target_size=(img_height, img_width)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\"Pic #\" + str(10))\n","\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeoAWiA67sxW","executionInfo":{"status":"ok","timestamp":1729772654800,"user_tz":-120,"elapsed":600,"user":{"displayName":"Kioshi Emerson","userId":"12312060826618643723"}},"outputId":"0d3783ac-fcc1-47a8-e773-7354d9453a58"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n","Pic #10\n","This image most likely belongs to Buy_-1 with a 72.29 percent confidence.\n"]}]}]}